{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 15:09:43,041 - pdfminer.pdfpage - WARNING - CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from data_extraction import extract_text_from_pdf, read_text_file\n",
    "\n",
    "resume_tochi = extract_text_from_pdf('./sample_pdf/tochi.pdf')\n",
    "#print(extracted_text)\n",
    "de_job_text = read_text_file('./job_texts/DE.txt')\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 15:09:45,021 - numexpr.utils - INFO - NumExpr defaulting to 10 threads.\n",
      "/opt/anaconda3/envs/testenv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22545170456471447"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matcher import BiasedDocumentMatcher\n",
    "Amatcher = BiasedDocumentMatcher({\n",
    "    'remove_stopwords': True,\n",
    "    'lemmatize': True,\n",
    "    'similarity_method': 'bow',  # Can be 'tfidf' or 'bow'\n",
    "})\n",
    "\n",
    "Amatcher.calculate_similarity(resume_tochi, de_job_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Matches for FE2.txt:\n",
      "1. frontend_genie.txt: 0.31\n",
      "2. frontend_claude.txt: 0.28\n",
      "3. frontend.txt: 0.27\n",
      "4. tester.txt: 0.15\n",
      "5. accounting.txt: 0.13\n",
      "\n",
      "Top 5 Matches for FE.txt:\n",
      "1. frontend_genie.txt: 0.41\n",
      "2. frontend_claude.txt: 0.32\n",
      "3. frontend.txt: 0.31\n",
      "4. tester.txt: 0.12\n",
      "5. dataeng.txt: 0.06\n",
      "\n",
      "Top 5 Matches for TE.txt:\n",
      "1. tester.txt: 0.46\n",
      "2. frontend_genie.txt: 0.15\n",
      "3. accounting.txt: 0.12\n",
      "4. frontend_claude.txt: 0.11\n",
      "5. frontend.txt: 0.06\n",
      "\n",
      "Top 5 Matches for DE.txt:\n",
      "1. dataeng.txt: 0.69\n",
      "2. frontend_genie.txt: 0.15\n",
      "3. frontend.txt: 0.13\n",
      "4. frontend_claude.txt: 0.12\n",
      "5. accounting.txt: 0.09\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def main():\n",
    "    method = 'bow'\n",
    "    \n",
    "    Amatcher = BiasedDocumentMatcher({\n",
    "        'remove_stopwords': True,\n",
    "        'lemmatize': True,\n",
    "        'similarity_method': method,  # Can be 'tfidf' or 'bow'\n",
    "    })\n",
    "\n",
    "    Matchers = [ Amatcher]\n",
    "\n",
    "    # Directories containing the files\n",
    "    job_description_folder = 'job_texts'\n",
    "    resume_folder = 'resume_texts'\n",
    "\n",
    "    # Loop through files in the job description folder\n",
    "    for job_description_filename in os.listdir(job_description_folder):\n",
    "        job_description_path = os.path.join(job_description_folder, job_description_filename)\n",
    "        resume_similarities = []\n",
    "        \n",
    "        job_description = read_text_file(job_description_path).strip()\n",
    "\n",
    "        # Loop through files in the resume folder\n",
    "        for resume_filename in os.listdir(resume_folder):\n",
    "            resume_path = os.path.join(resume_folder, resume_filename)\n",
    "            resume = read_text_file(resume_path).strip()\n",
    "            res = [matcher.calculate_similarity(job_description, resume) for matcher in Matchers]\n",
    "            resume_similarities.append((res, resume_filename))\n",
    "\n",
    "        # Sort and print top matches (Sort by first similarity score)\n",
    "        resume_similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "        print()\n",
    "        print(f\"Top 5 Matches for {job_description_filename}:\")\n",
    "        for i, (res, resume_filename) in enumerate(resume_similarities[:5]):\n",
    "            score_str = ', '.join(f\"{s:.2f}\" for s in res)\n",
    "            print(f\"{i+1}. {resume_filename}: {score_str}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Top 5 Matches for FE2.txt:\n",
    "1. frontend_genie.txt: 0.31\n",
    "2. frontend_claude.txt: 0.28\n",
    "3. frontend.txt: 0.27\n",
    "4. tester.txt: 0.15\n",
    "5. accounting.txt: 0.13\n",
    "\n",
    "Top 5 Matches for FE.txt:\n",
    "1. frontend_genie.txt: 0.41\n",
    "2. frontend_claude.txt: 0.32\n",
    "3. frontend.txt: 0.31\n",
    "4. tester.txt: 0.12\n",
    "5. dataeng.txt: 0.06\n",
    "\n",
    "Top 5 Matches for TE.txt:\n",
    "1. tester.txt: 0.46\n",
    "2. frontend_genie.txt: 0.15\n",
    "3. accounting.txt: 0.12\n",
    "4. frontend_claude.txt: 0.11\n",
    "5. frontend.txt: 0.06\n",
    "\n",
    "Top 5 Matches for DE.txt:\n",
    "1. dataeng.txt: 0.69\n",
    "2. frontend_genie.txt: 0.15\n",
    "3. frontend.txt: 0.13\n",
    "4. frontend_claude.txt: 0.12\n",
    "5. accounting.txt: 0.09"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
